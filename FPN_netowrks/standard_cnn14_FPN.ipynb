{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to represent the audio in the format as computer understand and to make the model learn the important characteristics of the audio sample, we need to extract perfect values from the audio signals.\n",
    "There are mainly 2 types of feature engineering:\n",
    "1. hand made features \n",
    "2. using the direct method to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract MFCC features from the audio and create dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating dataloaders\n",
    "source for the code: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction for audiodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Audiodataset(Dataset):\n",
    "    def __init__(self, audio_files, labels, transform=None, max_length=256):\n",
    "        self.audio_files = audio_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_files[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(audio_path, sr=32000)\n",
    "\n",
    "        # Filter out zero-length audio files\n",
    "        if len(y) == 0:\n",
    "            print(f\"Warning: {audio_path} has zero length.\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        # Convert to Mel spectrogram\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64, fmin=50, fmax=14000)\n",
    "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        # Normalize the log Mel spectrogram (standardization)\n",
    "        mean = np.mean(log_mel_spectrogram, axis=1, keepdims=True)\n",
    "        std = np.std(log_mel_spectrogram, axis=1, keepdims=True)\n",
    "        log_mel_spectrogram = (log_mel_spectrogram - mean) / std\n",
    "\n",
    "        # Pad or trim to max_length\n",
    "        if log_mel_spectrogram.shape[1] < self.max_length:\n",
    "            pad_width = self.max_length - log_mel_spectrogram.shape[1]\n",
    "            log_mel_spectrogram = np.pad(log_mel_spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            log_mel_spectrogram = log_mel_spectrogram[:, :self.max_length]\n",
    "\n",
    "        if self.transform:\n",
    "            log_mel_spectrogram = self.transform(log_mel_spectrogram)\n",
    "\n",
    "        log_mel_spectrogram = torch.tensor(log_mel_spectrogram, dtype=torch.float32).unsqueeze(0)  # Shape [1, time_steps, mel_bins]\n",
    "        log_mel_spectrogram = log_mel_spectrogram.permute(0, 2, 1)  # Shape [1, mel_bins, time_steps]\n",
    "        \n",
    "        return log_mel_spectrogram, torch.tensor(label, dtype=torch.long)  # Ensure label is a long tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing the data for training using dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train_dataloader=1508\n",
      "data loaders are ready for training step\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#define classes\n",
    "classes = ['Baby_Cry','Door_Knock','Door_Bell','Fire_Alarm']\n",
    "image_dir = \"C:\\\\Users\\\\PC\\\\Desktop\\\\lisnen_data\\\\audio_files\\\\audio_files\"\n",
    "\n",
    "audio_files = []\n",
    "labels = []\n",
    "\n",
    "for label, class_name in enumerate(classes):   #by using enumerate here we're saving index fo an element in label and its value in class_name\n",
    "    class_dir = os.path.join(image_dir,class_name)\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        # check if te file format is valid\n",
    "        if file_name.endswith('.wav'):  #coz we're working only on wav files\n",
    "            audio_files.append(os.path.join(class_dir,file_name))\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "# crating the data splits from audio_files to train, val and test splits\n",
    "training_audio,dummy_training_audio,training_labels,dummy_training_labels = train_test_split(audio_files,labels,test_size=0.2,shuffle=True,random_state=42)\n",
    "val_audio,test_audio,val_labels,test_labels = train_test_split(dummy_training_audio,dummy_training_labels,test_size=0.5,shuffle=True,random_state=42)\n",
    "\n",
    "# save the log mel values in the list format and then create dataloaders\n",
    "training_data  = Audiodataset(training_audio,training_labels,max_length=256)\n",
    "validation_data = Audiodataset(val_audio,val_labels,max_length=256)\n",
    "test_data = Audiodataset(test_audio,test_labels,max_length=256)\n",
    "\n",
    "# creating the data loaders\n",
    "train_dataloader = DataLoader(training_data,batch_size=16,shuffle = True)\n",
    "val_data_loader = DataLoader(validation_data,batch_size=16,shuffle=False)\n",
    "test_data_loader = DataLoader(test_data,batch_size=16,shuffle=False)\n",
    "print(f'len of train_dataloader={len(train_dataloader.dataset)}')\n",
    "print(\"data loaders are ready for training step\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining backbone network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a backbone cnn network \n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\PC\\\\Desktop\\\\lisnen_research_files\\\\lisnen_research_files\\\\audioset_tagging_cnn\\\\pytorch\")\n",
    "from models import Cnn14\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self,sample_rate,window_size,hop_size,mel_bins,fmin,fmax,classes_num):\n",
    "        super(Backbone, self).__init__()\n",
    "        # Initialize Cnn14\n",
    "        self.cnn14 = Cnn14(sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num)\n",
    "        # Replace the initial layers to accept Mel spectrograms directly\n",
    "        self.cnn14.spectrogram_extractor = nn.Identity()\n",
    "        self.cnn14.logmel_extractor = nn.Identity()\n",
    "        self.cnn14.fc1 = nn.Identity()\n",
    "        self.cnn14.fc_audioset = nn.Identity()\n",
    "        \n",
    "        # Adjust the SpecAugmentation parameters\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "                                               freq_drop_width=8, freq_stripes_num=2)\n",
    "        # input shape of tensor is (batch_size,no_of_channels,height,width)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(f'sape before augmentation ={x.shape}')\n",
    "        x = self.spec_augmenter(x)\n",
    "        #print(f'input shape = {x.shape}')\n",
    "        c1 = self.cnn14.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "        # as per cnn14 in_channels = 1, out_channels = 64\n",
    "        #print('shape of c1 ',c1.shape)\n",
    "        c2 = self.cnn14.conv_block2(c1, pool_size=(2, 2), pool_type='avg')\n",
    "        # as per cnn14 in_channels = 64, out_channels = 128\n",
    "        #print('shape of c2 ',c2.shape)\n",
    "        c3 = self.cnn14.conv_block3(c2, pool_size=(2, 2), pool_type='avg')\n",
    "        #print('shape of c3 ',c3.shape)\n",
    "        c4 = self.cnn14.conv_block4(c3, pool_size=(2, 2), pool_type='avg')\n",
    "        #print('shape of c4 ',c4.shape)\n",
    "        c5 = self.cnn14.conv_block5(c4, pool_size=(2, 2), pool_type='avg')\n",
    "        #print('shape of c5 ',c5.shape)\n",
    "        c6 = self.cnn14.conv_block6(c5,pool_size = (1,1), pool_type='avg')\n",
    "        #print('shape of c6 ',c6.shape)\n",
    "\n",
    "        return c1,c2, c3, c4, c5,c6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Feature pyramid network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FPNWithBackbone(nn.Module):\n",
    "    def __init__(self, backbone,num_classes):\n",
    "        super(FPNWithBackbone, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        \n",
    "        # Lateral convolutions to match the number of channels from backbone layers\n",
    "        self.lateral_conv1 = nn.Conv2d(64, 256, kernel_size=1, stride=1, padding=0)  #64= input channels, 256=output channels\n",
    "        self.lateral_conv2 = nn.Conv2d(128, 256, kernel_size=1, stride=1, padding=0) #128= input channels,256=output channels\n",
    "        self.lateral_conv3 = nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0)  \n",
    "        self.lateral_conv4 = nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0)   \n",
    "        self.lateral_conv5 = nn.Conv2d(1024, 256, kernel_size=1, stride=1, padding=0)   \n",
    "        self.lateral_conv6 = nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=0)   \n",
    "\n",
    "        # Additional layers after FPN\n",
    "        self.conv1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        #final_output_layre\n",
    "        # Final classification layer\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.fc1 = nn.Linear(256,2048, bias=True)\n",
    "        self.fc_audioset = nn.Linear(2048, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone forward pass\n",
    "        c1, c2, c3, c4, c5, c6 = self.backbone(x)\n",
    "        \n",
    "        # FPN layers\n",
    "        p6 = self.lateral_conv6(c6)  #lateral conv layer is used to equlaize no of channels\n",
    "        #print(f'shape of p6 ={p6.shape}')\n",
    "        p5 = self.lateral_conv5(c5) + p6\n",
    "        #print(f'shape of p5={p5.shape}')\n",
    "        p4 = self.lateral_conv4(c4) + F.interpolate(p5, scale_factor=2, mode='nearest')\n",
    "        #print(f'shape of p4={p4.shape}')\n",
    "        p3 = self.lateral_conv3(c3) + F.interpolate(p4, scale_factor=2, mode='nearest')\n",
    "        #print(f'shape of p3={p3.shape}')\n",
    "        p2 = self.lateral_conv2(c2) + F.interpolate(p3, scale_factor=2, mode='nearest')\n",
    "        #print(f'shape of p2={p2.shape}')\n",
    "        p1 = self.lateral_conv1(c1) + F.interpolate(p2, scale_factor=2, mode='nearest')\n",
    "        #print(f'shape of p1={p1.shape}')\n",
    "        \n",
    "        # Additional layers\n",
    "        out = self.conv1(p1)\n",
    "        #print('con layer 1 output shape=',out.shape)\n",
    "        #out = F.relu(out)\n",
    "        #out = self.max_pool1(out)  # First pooling\n",
    "        out = self.conv2(out)\n",
    "        #print('conv layer2 output shape=',out.shape)\n",
    "        #out = F.relu(out)\n",
    "        #out = self.max_pool2(out)  # Second pooling\n",
    "        #out = self.global_avg_pool(out)\n",
    "        out = self.max_pool(out)\n",
    "        #print('max pooling output shape',out.shape)\n",
    "        \n",
    "        # Flatten and pass through the final fully connected layer\n",
    "        # out = self.fc(out)  # No activation function here\n",
    "        # out = F.softmax(out,dim=1)\n",
    "        out = self.global_avg_pool(out)\n",
    "        #print('global avg pooling output shape = ',out.shape)\n",
    "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
    "        #print('shape after flattening',out.shape)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        #print('shape affter fc layer',out.shape)\n",
    "        output_class = torch.softmax(self.fc_audioset(out),dim=1)\n",
    "        #print(output_class)\n",
    "\n",
    "        \n",
    "        return output_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the required parameters\n",
    "sample_rate = 32000\n",
    "window_size = 1024\n",
    "hop_size = 320\n",
    "mel_bins = 64\n",
    "fmin = 50\n",
    "fmax = 14000\n",
    "classes_num = 4  # Number of classes in your dataset\n",
    "\n",
    "# Initialize the modified model\n",
    "backbone = Backbone(sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num)\n",
    "fpn_model = FPNWithBackbone(backbone,num_classes = classes_num)\n",
    "fpn_model= fpn_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPNWithBackbone(\n",
       "  (backbone): Backbone(\n",
       "    (cnn14): Cnn14(\n",
       "      (spectrogram_extractor): Identity()\n",
       "      (logmel_extractor): Identity()\n",
       "      (spec_augmenter): SpecAugmentation(\n",
       "        (time_dropper): DropStripes()\n",
       "        (freq_dropper): DropStripes()\n",
       "      )\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_block1): ConvBlock(\n",
       "        (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block2): ConvBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block3): ConvBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block4): ConvBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block5): ConvBlock(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block6): ConvBlock(\n",
       "        (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc1): Identity()\n",
       "      (fc_audioset): Identity()\n",
       "    )\n",
       "    (spec_augmenter): SpecAugmentation(\n",
       "      (time_dropper): DropStripes()\n",
       "      (freq_dropper): DropStripes()\n",
       "    )\n",
       "  )\n",
       "  (lateral_conv1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (lateral_conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (lateral_conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (lateral_conv4): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (lateral_conv5): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (lateral_conv6): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "  (fc_audioset): Linear(in_features=2048, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pre trained weights\n",
    "import torch\n",
    "pretrained_path = \"C:\\\\Users\\\\PC\\\\Downloads\\\\cnn14_fine_tuned_model.pth\"  # Update this path to your pretrained model file\n",
    "checkpoint = torch.load(pretrained_path, map_location=torch.device('cuda'))\n",
    "\n",
    "# Load the pretrained weights, except for the final layer\n",
    "model_dict = backbone.state_dict()\n",
    "pretrained_dict = {k: v for k, v in checkpoint.items() if k in model_dict and 'fc_audioset' not in k}\n",
    "model_dict.update(pretrained_dict)\n",
    "backbone.load_state_dict(model_dict)\n",
    "fpn_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating training function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the training function\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    accumulation_steps = 4\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            #print(f'shape of inputs={inputs.shape}')\n",
    "            #print(f'shape of labels={labels.shape}')\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)  # Outputs should be [batch_size, num_classes]\n",
    "\n",
    "            loss = criterion(outputs, labels)  # Criterion expects outputs and labels in the correct shape\n",
    "            loss = loss / accumulation_steps  # Normalize loss\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_running_loss / len(val_loader)\n",
    "        val_epoch_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_epoch_accuracy:.2f}%\")\n",
    "\n",
    "        # # Save the model if the validation accuracy is the best we've seen so far.\n",
    "        # if val_epoch_accuracy > best_val_accuracy:\n",
    "        #     best_val_accuracy = val_epoch_accuracy\n",
    "        #     torch.save(model.state_dict(), 'best_model.pth')\n",
    "        #     print(f\"Model saved with validation accuracy: {val_epoch_accuracy:.2f}%\")\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization function\n",
    "\n",
    "#train_losses, train_accuracies, val_losses, val_accuracies \n",
    "def visualize(train_accuracies,val_accuracies,train_losses,val_losses,num_epochs):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs+1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, num_epochs+1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25:   0%|          | 0/95 [00:00<?, ?it/s]C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_19108\\4013699460.py:35: RuntimeWarning: invalid value encountered in divide\n",
      "  log_mel_spectrogram = (log_mel_spectrogram - mean) / std\n",
      "Epoch 1/25:  16%|█▌        | 15/95 [00:05<00:25,  3.17it/s]c:\\Users\\PC\\anaconda3\\envs\\fpn_pytorch\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1505\n",
      "  warnings.warn(\n",
      "Epoch 1/25: 100%|██████████| 95/95 [00:29<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:02<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 95/95 [00:19<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 95/95 [00:19<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 95/95 [00:19<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 95/95 [00:19<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 95/95 [00:19<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 95/95 [00:19<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 95/95 [00:19<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 95/95 [00:19<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 95/95 [00:19<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 95/95 [00:20<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 95/95 [00:19<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|██████████| 95/95 [00:19<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|██████████| 95/95 [00:19<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|██████████| 95/95 [00:19<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Train Loss: nan, Train Accuracy: 31.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 12/12 [00:01<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Val Loss: nan, Val Accuracy: 31.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25:  37%|███▋      | 35/95 [00:07<00:12,  4.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)  \u001b[38;5;66;03m# Reduce lr by 0.1 every 10 epochs\u001b[39;00m\n\u001b[0;32m     12\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[1;32m---> 14\u001b[0m train_losses, train_accuracies, val_losses, val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     41\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 43\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     45\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# Initialize CNN14 backbone\n",
    "#backbone = Backbone_Cnn14(sample_rate=32000, window_size=1024, hop_size=320, mel_bins=32, fmin=50, fmax=14000, classes_num=4)\n",
    "\n",
    "# Initialize FPN\n",
    "#model = FPNWithBackbone(backbone)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(fpn_model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Reduce lr by 0.1 every 10 epochs\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "train_losses, train_accuracies, val_losses, val_accuracies = train(fpn_model, train_dataloader, val_data_loader, criterion, optimizer, scheduler,num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(train_accuracies,val_accuracies,train_losses,val_losses,num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpn_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
